{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleksandr62aa/YOLOv8_Tracking/blob/main/Yolo_DeepSort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3LsYecndup0"
      },
      "source": [
        "**Detect YOLO + DeepSORT an video**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WbKuhVIEQH8"
      },
      "outputs": [],
      "source": [
        "# Setup YOLO\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "import ultralytics\n",
        "ultralytics.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the Github Repo\n",
        "!git clone https://github.com/Aleksandr62aa/YOLOv8_Tracking.git\n",
        "!pip install filterpy\n",
        "%cd YOLOv8_Tracking"
      ],
      "metadata": {
        "id": "nIrFZoc6vRww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1jLYQ-X1eKc-"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "from sort import Sort\n",
        "from deepsort_tracker import Tracker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect YOLO + DeepSORT\n",
        "class YoloDeepSORT:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        print(\"Using Device: \", self.device)\n",
        "        self.model = self.load_model()\n",
        "        self.CLASS_NAMES_DICT = self.model.model.names\n",
        "\n",
        "    def load_model(self):\n",
        "\n",
        "        model = YOLO(\"yolov8n.pt\")  # load a pretrained YOLOv8n model\n",
        "        model.fuse()\n",
        "\n",
        "        return model\n",
        "\n",
        "    def predict(self, frame):\n",
        "\n",
        "        results = self.model(frame, classes=0, conf=0.3, verbose=False)\n",
        "        # results = model(frame, classes=(1, 2 ,3, 5, 7), conf=0.8, verbose=False)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def get_results(self, results):\n",
        "\n",
        "        detections_list = []\n",
        "        # Extract detections\n",
        "        for result in results[0]:\n",
        "            bbox = result.boxes.xyxy.cpu().numpy()\n",
        "            confidence = result.boxes.conf.cpu().numpy()\n",
        "            merged_detection = [bbox[0][0], bbox[0][1], bbox[0][2], bbox[0][3], confidence[0]]\n",
        "            detections_list.append(merged_detection)\n",
        "\n",
        "        return np.array(detections_list)\n",
        "\n",
        "    def draw_bounding_boxes_with_id(self, img, bboxes, ids):\n",
        "\n",
        "        for bbox, id_ in zip(bboxes, ids):\n",
        "            cv2.rectangle(img,(int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])),(0,0,255),2)\n",
        "            cv2.putText(img, \"ID: \" + str(id_), (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __call__(self):\n",
        "\n",
        "        video_path = '/content/test3.mp4'\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        assert cap.isOpened()\n",
        "\n",
        "        # Get the video properties\n",
        "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # Define the codec and create VideoWriter object\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "        # Output the video path\n",
        "        video_out_path = 'output_DeepSORT.avi'\n",
        "        out = cv2.VideoWriter(video_out_path, fourcc, 10, (frame_width, frame_height))\n",
        "\n",
        "        # DeepSORT\n",
        "        tracker = Tracker()\n",
        "\n",
        "        counter = 0\n",
        "        start_time = time.perf_counter()\n",
        "\n",
        "        while cap.isOpened():\n",
        "\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                results = self.predict(frame)\n",
        "                detections_list = self.get_results(results)\n",
        "\n",
        "                # DeepSORT Tracking\n",
        "                if len(detections_list) == 0:\n",
        "                    detections_list = np.empty((0, 5))\n",
        "\n",
        "                tracker.update(frame, detections_list)\n",
        "\n",
        "                boxes_track = []\n",
        "                boxes_ids = []\n",
        "                for track in tracker.tracks:\n",
        "                    bbox = track.bbox\n",
        "                    x1, y1, x2, y2 = bbox\n",
        "                    track_id = track.track_id\n",
        "                    boxes_track.append([x1, y1, x2, y2])\n",
        "                    boxes_ids.append(track_id )\n",
        "\n",
        "                frame = self.draw_bounding_boxes_with_id(frame, boxes_track, boxes_ids)\n",
        "\n",
        "                # Update FPS and place on frame\n",
        "                current_time = time.perf_counter()\n",
        "                elapsed = (current_time - start_time)\n",
        "                counter += 1\n",
        "                if elapsed > 1:\n",
        "                    fps = counter / elapsed\n",
        "                    counter = 0\n",
        "                    start_time = current_time\n",
        "\n",
        "                cv2.putText(frame, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
        "                out.write(frame)\n",
        "\n",
        "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "                    break\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "JTjppGQmuJMt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = YoloDeepSORT()\n",
        "detector()"
      ],
      "metadata": {
        "id": "_zzRAgXZZ-ea"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}